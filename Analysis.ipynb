{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "* in association of students with ACM, filter for active students. They are already naturally filtered for students who have received >0 minutes of tutoring. Alternatively, define 'active' as a student who has received >200 mins tutoring, or create some composite score that scales student assessment performance by tutoring time received\n",
    "* teacher surveys\n",
    "    * associate ACMs with teachers\n",
    "* Conditions for success\n",
    "* more survey items that were interesting from Q1\n",
    "* incorporate Q2 and Q3 survey\n",
    "\n",
    "# Next Steps/Cycle\n",
    "1. decide attributes\n",
    "    * dimensionality reduction, represent dataset with less data,but less transparency (PCA)\n",
    "    * norm responses within individual responses (z-score seems standard here)\n",
    "    * all if I can norm/encode programatically, then research feature selection scoring methods\n",
    "    * use intuition/attributes I know are important\n",
    "* Decide what scoring method to best select attributes\n",
    "* Create decision tree\n",
    "* Test other targets (measures of ACM effectiveness)\n",
    "\n",
    "# Analysis Questions\n",
    "* visualize tutoring time against growth\n",
    "* visualize O&C scores against growth\n",
    "* visualize growth against test date (whether baseline came from prior year or from fall)\n",
    "* do SYACMs have greater impact? do they have greater impact when working with the same students?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "# import pymc3 as pm\n",
    "import seaborn as sns; sns.set_context('notebook')\n",
    "os.chdir(r'Z:\\ChiPrivate\\Chicago Reports and Evaluation\\SY18\\Eval Management\\ACM_analysis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load shaped tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Student-level: tutoring time sum by student-program and associated to staff id via sections\n",
    "tut_time_df = pd.read_csv('time_on_task_2017-12-11.csv')\n",
    "# Student-level: Assessment performance vs target, no student-staff associations\n",
    "assmt_df = pd.read_csv('assessment_growth.csv')\n",
    "# ACM-level: each coaching instance YTD\n",
    "heatmaps_df = pd.read_csv('OC_clean.csv')\n",
    "# ACM-level: coaching data aggregated and normed, up to December\n",
    "heatmaps_df_agg = pd.read_csv('OC_clean_agg.csv')\n",
    "# ACM-level: Surveys\n",
    "survey_df = pd.read_csv('ACM_surveys.csv')\n",
    "# ACM-level: Projected Commute Time\n",
    "commutes_df = pd.read_csv('commutes_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge assessments to tutoring time (including student-staff associations)\n",
    "assmt_df['Assessment Type'] = assmt_df['Assessment Type'].str.replace('NWEA - ELA', 'Tutoring: Literacy')\n",
    "assmt_df['Assessment Type'] = assmt_df['Assessment Type'].str.replace('NWEA - MATH', 'Tutoring: Math')\n",
    "assmt_df['Key'] = assmt_df['Student__c'] + assmt_df['Assessment Type']\n",
    "del assmt_df['Student__c']\n",
    "tut_time_df['Key'] = tut_time_df['Student__c'] + tut_time_df['Program__c_Name']\n",
    "impact_df = assmt_df.merge(tut_time_df, on='Key')\n",
    "impact_df = impact_df.loc[impact_df['ToT_sum']>=90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impact_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # experiment with scaling assessment growth by amount of time served by ACM\n",
    "# impact_df.loc[impact_df['Hit_Target?']==1, 'Score_scaled_tot'] = impact_df['Amount_of_Time__c_YTD']\n",
    "# impact_df.loc[impact_df['Hit_Target?']==0, 'Score_scaled_tot'] = -1*impact_df['Amount_of_Time__c_YTD']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "response_i,c=α+β∗predictor_i,c+ϵ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = impact_df[['Staff__c', 'ToT_mean', 'Growth_v_Target']]\n",
    "data = data.sort_values('Staff__c')\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "data.loc[:, 'Staff__c_code'] = data.Staff__c.map(dict(zip(data.Staff__c.unique(), list(range(0, len(data.Staff__c.unique()))))))\n",
    "acms_idx = data.Staff__c_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as hierarchical_model:\n",
    "    # Hyperpriors\n",
    "    mu_a = pm.Normal('mu_alpha', mu=0., sd=1)\n",
    "    sigma_a = pm.HalfCauchy('sigma_alpha', beta=1)\n",
    "    mu_b = pm.Normal('mu_beta', mu=0., sd=1)\n",
    "    sigma_b = pm.HalfCauchy('sigma_beta', beta=1)\n",
    "    \n",
    "    # Intercept for each county, distributed around group mean mu_a\n",
    "    a = pm.Normal('alpha', mu=mu_a, sd=sigma_a, shape=len(data.Staff__c.unique()))\n",
    "    # Intercept for each county, distributed around group mean mu_a\n",
    "    b = pm.Normal('beta', mu=mu_b, sd=sigma_b, shape=len(data.Staff__c.unique()))\n",
    "    \n",
    "    # Model error\n",
    "    eps = pm.HalfCauchy('eps', beta=1)\n",
    "    \n",
    "    # Expected value\n",
    "    growth_est = a[acms_idx] + b[acms_idx] * data.ToT_mean.values\n",
    "    \n",
    "    # Data likelihood\n",
    "    y_like = pm.Normal('y_like', mu=growth_est, sd=eps, observed=data.Growth_v_Target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with hierarchical_model:\n",
    "    hierarchical_trace = pm.sample(njobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pm.traceplot(hierarchical_trace);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impact_df['ToT_sum'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impact_df['ToT_count'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impact_df['ToT_mean'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "impact_df['Growth_v_Target'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Does Tutoring Time Relate to Assessment Growth?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(data=impact_df, x='ToT_mean', y='Growth_v_Target', hue='Staff__c', legend=False, size=6, ci=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(data=impact_df.loc[impact_df['Staff__c']=='a1L1a0000035cbTEAQ'], x='ToT_count', y='Growth_v_Target', legend=False, hue='Staff__c', size=6, ci=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_size = 20\n",
    "bin_range = (impact_df['ToT_sum'].max() - impact_df['ToT_sum'].min())/bin_size\n",
    "impact_df.loc[:, 'ToT_sum_binned'] = pd.cut(impact_df['ToT_sum'], bin_size, labels=False)\n",
    "impact_df.loc[:, 'ToT_sum_binned'] = (impact_df.loc[:, 'ToT_sum_binned']+1) * bin_range\n",
    "sns.lmplot(data=impact_df, x='ToT_sum_binned', y='Growth_v_Target', order=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(data=impact_df, x='ToT_sum', y='Hit_Target?', hue='Staff__c', size=10, legend=False, ci=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic=True failed\n",
    "sns.lmplot(data=impact_df, x='ToT_sum', y='Hit_Target?', hue='Staff__c', size=10, legend=False, ci=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # group to ACM level\n",
    "# group1_df = impact_df.groupby('Staff__c').agg(['sum', 'mean', 'std', 'count']).reset_index()\n",
    "# group1_df.columns = [' '.join(col).strip() for col in group1_df.columns.values]\n",
    "# group2_df = impact_df.groupby('Staff__c')['School__c'].first().reset_index()\n",
    "# impact_df = group1_df.merge(group2_df, on='Staff__c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impact_df['Score_scaled_tot'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimenting with Different Scoring methods to aggregate student performance by ACM\n",
    "Place greater value on N students who met target, penalize for N students who missed. [Graph](https://academo.org/demos/3d-surface-plotter/?expression=y%5E1.5-x%5E1.3&xRange=0%2C%2B12&yRange=0%2C%2B12&resolution=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impact_df['N Hit Target'] = impact_df['Hit_Target? mean'] * impact_df['Hit_Target? count']\n",
    "impact_df['N Not Hit Target'] = impact_df['Hit_Target? count'] - impact_df['N Hit Target']\n",
    "impact_df['Score'] = impact_df['N Hit Target']**1.5 - impact_df['N Not Hit Target']**1.3\n",
    "# z-score normalization\n",
    "impact_df['Score'] = (impact_df['Score'] - impact_df['Score'].mean()) / impact_df['Score'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "impact_df['Score'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.lmplot(data=impact_df, x='School__c', y='Amount_of_Time__c_YTD mean', hue='Score', palette=\"RdBu\", fit_reg=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x=\"School__c\", y=\"Score\", data=impact_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xticks(rotation=90)\n",
    "sns.stripplot(x=\"School__c\", y=\"Score\", data=impact_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tut_time_df.loc[tut_time_df.Amount_of_Time__c_YTD<200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_df.reset_index(inplace=True)\n",
    "# df = mean_df.merge(survey_df, on='Staff__c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn_pandas import DataFrameMapper\n",
    "# import numpy as np\n",
    "# import sklearn.preprocessing, sklearn.decomposition, sklearn.linear_model, sklearn.pipeline, sklearn.metrics\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "# mapper = DataFrameMapper([('NPS', sklearn.preprocessing.LabelBinarizer()),\n",
    "#                           ('Growth_v_Target mean', None)], df_out=True)\n",
    "\n",
    "# mapper\n",
    "\n",
    "# mapper_fs = DataFrameMapper([(['children','salary'], SelectKBest(chi2, k=1))])\n",
    "# mapper_fs.fit_transform(data[['children','salary']], data['Growth_v_Target mean'])\n",
    "\n",
    "# from sklearn import tree\n",
    "\n",
    "# X = [[0, 0], [1, 1]]\n",
    "# Y = [0, 1]\n",
    "# clf = tree.DecisionTreeClassifier()\n",
    "# clf = clf.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x='Score', y=\"Amount_of_Time__c_YTD mean\", data=impact_df, kind=\"kde\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x=\"Growth_v_Target mean\", y=\"Amount_of_Time__c_YTD mean\", data=impact_df, kind=\"kde\", xlim=(-20, 20), ylim=(0, 1200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_df[(\"Growth_v_Target\", \"mean\")].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mean_df[(\"Hit_Target?\", \"mean\")].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare O&C to Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oc_df = heatmaps_df_agg.merge(impact_df[['Staff__c', 'Score', 'Hit_Target? mean']], on='Staff__c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(oc_df, x_vars=['Plan Rating', 'ET Rating','ESE Rating','SPM Rating','Learn Rating'], \n",
    "             y_vars=['Score'], kind=\"reg\", hue='Coach', size=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.pairplot(oc_df, x_vars=[col for col in oc_df.columns if '_norm' in col], \n",
    "             y_vars=['Score'], kind=\"reg\", hue='Coach', size=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.pairplot(oc_df, x_vars=[col for col in oc_df.columns if '_norm' in col], \n",
    "             y_vars=['Score'], kind=\"reg\", size=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Survey to Commutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surv_commute_df = survey_df.copy()\n",
    "surv_commute_df = surv_commute_df.merge(commutes_df, on='Staff__c', how='left')\n",
    "\n",
    "surv_commute_df.loc[:, 'Q2_var51O96'] = surv_commute_df.loc[:, 'Q2_var51O96'].map({'Checked':1, 'Unchecked':0})\n",
    "surv_commute_df.loc[:, 'Q3_var31'] = pd.to_numeric(surv_commute_df['Q3_var31'], errors='coerce')\n",
    "surv_commute_df.loc[surv_commute_df['Commute.Time'] > 900, 'Commute.Time'] = np.nan\n",
    "surv_commute_df.loc[surv_commute_df['Q3_var31'] > 900, 'Q3_var31'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pryr_commute = pd.read_excel('FY17 Corps Housing Survey.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Self-Reported Commute minus Predicted Commute\n",
    "binwidth = 15\n",
    "minx=0\n",
    "maxx=150\n",
    "plt.xticks(range(minx, maxx, binwidth))\n",
    "data = pryr_commute['How long is your commute to your school (one way)?']\n",
    "data.hist(bins=range(minx, maxx, binwidth), normed=True)\n",
    "data = surv_commute_df.loc[(~surv_commute_df['Q3_var31'].isnull() &\n",
    "                            ~surv_commute_df['Commute.Time'].isnull()),\n",
    "                           'Q3_var31']\n",
    "ax = data.hist(bins=range(minx, maxx, binwidth), alpha=.6, normed=True)\n",
    "\n",
    "vals = ax.get_yticks()\n",
    "ax.set_yticklabels(['{:3.0f}%'.format(x*1000) for x in vals])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Likelihood of Listing Commute as a Challenge (Y axis) vs. Predicted Commute (X axis)\n",
    "sns.lmplot(x='Commute.Time', y='Q2_var51O96', data=surv_commute_df, logistic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Likelihood of Listing Commute as a Challenge (Y axis) vs. Self-Reported Commute (X axis)\n",
    "sns.lmplot(x='Q3_var31', y='Q2_var51O96', data=surv_commute_df, logistic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "surv_commute_df.loc[:, 'Actual_vs_Predicted'] = surv_commute_df['Q3_var31'] - surv_commute_df['Commute.Time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surv_commute_df['Q3_var32'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Self-Reported Commute minus Predicted Commute\n",
    "binwidth = 10\n",
    "plt.xticks(range(-100, 100, 20))\n",
    "data = surv_commute_df.loc[(~surv_commute_df['Q3_var31'].isnull() &\n",
    "                            ~surv_commute_df['Commute.Time'].isnull() &\n",
    "                            surv_commute_df['Q3_var32'].str.contains('Car')), \n",
    "                           'Actual_vs_Predicted']\n",
    "data.hist(bins=range(-100, 100, binwidth))\n",
    "data = surv_commute_df.loc[(~surv_commute_df['Q3_var31'].isnull() &\n",
    "                            ~surv_commute_df['Commute.Time'].isnull() & \n",
    "                            surv_commute_df['Q3_var32'].str.contains('Public transit')),\n",
    "                           'Actual_vs_Predicted']\n",
    "data.hist(bins=range(-100, 100, binwidth), alpha=.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Self-Reported Commute and Predicted Commute\n",
    "binwidth = 10\n",
    "plt.xticks(range(0, 200, 20))\n",
    "data = surv_commute_df.loc[(~surv_commute_df['Q3_var31'].isnull() & ~surv_commute_df['Commute.Time'].isnull()), 'Commute.Time']\n",
    "data.hist(bins=range(0, 175, binwidth))\n",
    "data = surv_commute_df.loc[(~surv_commute_df['Q3_var31'].isnull() & ~surv_commute_df['Commute.Time'].isnull()), 'Q3_var31']\n",
    "data.hist(alpha=0.6, bins=range(0, 175, binwidth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Surveys to Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_df = survey_df.merge(impact_df[['Staff__c', 'Score', 'Hit_Target? mean']], on='Staff__c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xticks(rotation=90)\n",
    "sns.swarmplot(x=\"Educational.Attainment\", y=\"Score\", data=survey_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# var5\tvar31\tvar76\tvar77\tvar79\tvar80\tvar85\tvar86\tvar87\tvar88\n",
    "sns.jointplot(x=\"var88\", y=\"Score\", data=survey_df, kind='reg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.swarmplot(x=\"var88\", y=\"Score\", data=survey_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_df.loc[survey_df['Tutoring.Experience.Months'].isnull(), 'Tutoring.Experience.Months'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x=\"Tutoring.Experience.Months\", y=\"Score\", data=survey_df, order=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xticks(rotation=90)\n",
    "sns.swarmplot(x=\"var31\", y=\"Score\", data=survey_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.regplot(x=\"Age\", y=\"Score\", data=survey_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
